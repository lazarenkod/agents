# Knative Service Examples
# Production-ready Knative Service configurations for various use cases

---
# Example 1: Basic HTTP Service with Scale-to-Zero
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: hello-service
  namespace: default
  labels:
    app: hello-service
    tier: frontend
spec:
  template:
    metadata:
      annotations:
        # Auto-scaling configuration
        autoscaling.knative.dev/min-scale: "0"
        autoscaling.knative.dev/max-scale: "10"
        autoscaling.knative.dev/target: "100"
        autoscaling.knative.dev/metric: "concurrency"
    spec:
      containers:
      - name: app
        image: gcr.io/knative-samples/helloworld-go
        ports:
        - containerPort: 8080
        env:
        - name: TARGET
          value: "World"
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 1000m
            memory: 512Mi

---
# Example 2: Production API Service with Database
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: api-service
  namespace: production
  labels:
    app: api-service
    version: v1
    tier: backend
spec:
  template:
    metadata:
      annotations:
        # Auto-scaling - RPS based
        autoscaling.knative.dev/min-scale: "2"
        autoscaling.knative.dev/max-scale: "100"
        autoscaling.knative.dev/target: "1000"
        autoscaling.knative.dev/metric: "rps"
        autoscaling.knative.dev/target-utilization-percentage: "70"

        # Cold start optimization
        autoscaling.knative.dev/activation-scale: "3"
        autoscaling.knative.dev/scale-down-delay: "15m"

        # Timeouts
        serving.knative.dev/timeout: "300s"
        serving.knative.dev/progress-deadline: "600s"

        # Networking
        serving.knative.dev/visibility: "cluster-local"

      labels:
        app: api-service
        version: v1
    spec:
      # Container concurrency
      containerConcurrency: 80
      timeoutSeconds: 300

      containers:
      - name: api
        image: myregistry.io/api-service:v1.2.0
        ports:
        - name: http1
          containerPort: 8080
          protocol: TCP

        env:
        # Database configuration
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: url
        - name: DATABASE_POOL_SIZE
          value: "20"
        - name: DATABASE_POOL_TIMEOUT
          value: "30"

        # Cache configuration
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: redis-credentials
              key: url
        - name: CACHE_ENABLED
          value: "true"
        - name: CACHE_TTL
          value: "3600"

        # Application configuration
        - name: LOG_LEVEL
          value: "info"
        - name: ENVIRONMENT
          value: "production"
        - name: MAX_REQUEST_SIZE
          value: "10485760"  # 10MB

        # Health check configuration
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 3

        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 2
          successThreshold: 1
          failureThreshold: 3

        # Startup probe for slow starting containers
        startupProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 0
          periodSeconds: 2
          timeoutSeconds: 1
          failureThreshold: 30

        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 4Gi

        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true

        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /cache

      volumes:
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir:
          medium: Memory
          sizeLimit: 512Mi

---
# Example 3: Machine Learning Inference Service
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: ml-inference
  namespace: ai
  labels:
    app: ml-inference
    model: yolov8
spec:
  template:
    metadata:
      annotations:
        # GPU-intensive workload - keep some replicas warm
        autoscaling.knative.dev/min-scale: "1"
        autoscaling.knative.dev/max-scale: "10"
        autoscaling.knative.dev/target: "5"
        autoscaling.knative.dev/metric: "concurrency"

        # Longer timeout for model inference
        serving.knative.dev/timeout: "120s"

        # Longer scale-down delay due to expensive cold starts
        autoscaling.knative.dev/scale-down-delay: "30m"

      labels:
        app: ml-inference
        model: yolov8
    spec:
      containerConcurrency: 5  # Limit concurrent requests for GPU

      containers:
      - name: inference
        image: myregistry.io/ml-inference:latest
        ports:
        - containerPort: 8080

        env:
        - name: MODEL_PATH
          value: "/models/yolov8n.onnx"
        - name: CONFIDENCE_THRESHOLD
          value: "0.5"
        - name: BATCH_SIZE
          value: "8"
        - name: USE_GPU
          value: "true"

        resources:
          requests:
            cpu: 2000m
            memory: 4Gi
            nvidia.com/gpu: "1"
          limits:
            cpu: 4000m
            memory: 8Gi
            nvidia.com/gpu: "1"

        volumeMounts:
        - name: models
          mountPath: /models
          readOnly: true

      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: ml-models

      nodeSelector:
        hardware: gpu-enabled

---
# Example 4: Event-Driven Function with Knative Eventing
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: order-processor
  namespace: events
  labels:
    app: order-processor
spec:
  template:
    metadata:
      annotations:
        # Scale based on events in queue
        autoscaling.knative.dev/min-scale: "1"
        autoscaling.knative.dev/max-scale: "50"
        autoscaling.knative.dev/target: "10"
        autoscaling.knative.dev/metric: "concurrency"
    spec:
      containers:
      - name: processor
        image: myregistry.io/order-processor:latest
        ports:
        - containerPort: 8080

        env:
        # Broker URL for emitting events
        - name: K_SINK
          value: "http://broker-ingress.knative-eventing.svc.cluster.local/events/default"

        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: url

        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 1Gi

---
# Example 5: Blue-Green Deployment with Traffic Splitting
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: frontend-app
  namespace: production
  labels:
    app: frontend-app
spec:
  traffic:
  # Blue (current production) - 90% traffic
  - revisionName: frontend-app-v1-blue
    percent: 90
    tag: blue

  # Green (new version) - 10% traffic
  - revisionName: frontend-app-v2-green
    percent: 10
    tag: green

  # Latest (not receiving traffic, but accessible via tag)
  - latestRevision: true
    percent: 0
    tag: latest

  template:
    metadata:
      name: frontend-app-v2-green
      annotations:
        autoscaling.knative.dev/min-scale: "3"
        autoscaling.knative.dev/max-scale: "50"
      labels:
        app: frontend-app
        version: v2
    spec:
      containers:
      - name: app
        image: myregistry.io/frontend-app:v2.0.0
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 512Mi

---
# Example 6: Private Service (Cluster-Local)
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: internal-api
  namespace: backend
  labels:
    app: internal-api
    visibility: private
spec:
  template:
    metadata:
      annotations:
        # Make service private (cluster-local only)
        serving.knative.dev/visibility: "cluster-local"

        autoscaling.knative.dev/min-scale: "2"
        autoscaling.knative.dev/max-scale: "20"
    spec:
      containers:
      - name: api
        image: myregistry.io/internal-api:latest
        ports:
        - containerPort: 8080
        env:
        - name: SERVICE_MODE
          value: "internal"
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi

---
# Example 7: Service with Init Container
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: db-migration-app
  namespace: production
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/min-scale: "1"
        autoscaling.knative.dev/max-scale: "10"
    spec:
      initContainers:
      # Run database migrations before starting app
      - name: db-migrate
        image: myregistry.io/db-migrator:latest
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: url
        command:
        - /bin/sh
        - -c
        - |
          echo "Running migrations..."
          /app/migrate up
          echo "Migrations complete"

      containers:
      - name: app
        image: myregistry.io/app:latest
        ports:
        - containerPort: 8080
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: url
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 1Gi

---
# Example 8: Multi-Container Service (Sidecar Pattern)
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: app-with-sidecar
  namespace: production
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/min-scale: "1"
        autoscaling.knative.dev/max-scale: "20"
    spec:
      containers:
      # Main application container
      - name: app
        image: myregistry.io/app:latest
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 1Gi

      # Logging sidecar
      - name: log-forwarder
        image: fluent/fluent-bit:latest
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.logging.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 128Mi

      volumes:
      - name: varlog
        emptyDir: {}

---
# Example 9: Service with Custom Domain
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: custom-domain-service
  namespace: production
  labels:
    app: custom-domain-service
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/min-scale: "2"
        autoscaling.knative.dev/max-scale: "50"
    spec:
      containers:
      - name: app
        image: myregistry.io/app:latest
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 1Gi
---
# DomainMapping for custom domain
apiVersion: serving.knative.dev/v1alpha1
kind: DomainMapping
metadata:
  name: api.example.com
  namespace: production
spec:
  ref:
    name: custom-domain-service
    kind: Service
    apiVersion: serving.knative.dev/v1

---
# Example 10: Queue Proxy Configuration
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: queue-tuned-service
  namespace: production
spec:
  template:
    metadata:
      annotations:
        # Auto-scaling
        autoscaling.knative.dev/min-scale: "2"
        autoscaling.knative.dev/max-scale: "100"
        autoscaling.knative.dev/target: "100"

        # Queue proxy configuration
        queue.sidecar.serving.knative.dev/resourcePercentage: "50"

        # Panic mode (rapid scale-up)
        autoscaling.knative.dev/panic-threshold-percentage: "200"
        autoscaling.knative.dev/panic-window-percentage: "10"

        # Stable window
        autoscaling.knative.dev/stable-window: "60s"
    spec:
      containerConcurrency: 100
      containers:
      - name: app
        image: myregistry.io/high-traffic-app:latest
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
          limits:
            cpu: 4000m
            memory: 8Gi
